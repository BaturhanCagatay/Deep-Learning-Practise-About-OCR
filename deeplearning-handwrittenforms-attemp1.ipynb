{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1840441,"sourceType":"datasetVersion","datasetId":1094263},{"sourceId":10477338,"sourceType":"datasetVersion","datasetId":6487569},{"sourceId":10477381,"sourceType":"datasetVersion","datasetId":6487599}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing Libraries\nimport os\nimport random\nfrom pathlib import Path\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tqdm.auto import tqdm\nfrom timeit import default_timer as timer\nimport cv2\nimport pytesseract\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nfrom torch.utils.data import DataLoader,random_split\nfrom torchvision import transforms, datasets","metadata":{"execution":{"iopub.status.busy":"2025-01-15T13:05:45.059092Z","iopub.execute_input":"2025-01-15T13:05:45.059411Z","iopub.status.idle":"2025-01-15T13:05:50.953300Z","shell.execute_reply.started":"2025-01-15T13:05:45.059381Z","shell.execute_reply":"2025-01-15T13:05:50.952663Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Function to go through the files.\ndef walk_through_dir(dir_path):\n  \"\"\"\n  Walks through dir_path returning its contents.\n  Args:\n    dir_path (str or pathlib.Path): target directory\n\n  Returns:\n    A print out of:\n      number of subdiretories in dir_path\n      number of images (files) in each subdirectory\n      name of each subdirectory\n  \"\"\"\n  for dirpath, dirnames, filenames in os.walk(dir_path):\n    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2025-01-15T13:05:50.954722Z","iopub.execute_input":"2025-01-15T13:05:50.955195Z","iopub.status.idle":"2025-01-15T13:05:50.959806Z","shell.execute_reply.started":"2025-01-15T13:05:50.955173Z","shell.execute_reply":"2025-01-15T13:05:50.959031Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"walk_through_dir(\"/kaggle/input/iam-handwritten-forms-dataset\")","metadata":{"_kg_hide-output":true,"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T13:05:50.960864Z","iopub.execute_input":"2025-01-15T13:05:50.961201Z","iopub.status.idle":"2025-01-15T13:05:53.619408Z","shell.execute_reply.started":"2025-01-15T13:05:50.961173Z","shell.execute_reply":"2025-01-15T13:05:53.618638Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice","metadata":{"execution":{"iopub.status.busy":"2025-01-15T13:05:53.620284Z","iopub.execute_input":"2025-01-15T13:05:53.620560Z","iopub.status.idle":"2025-01-15T13:05:53.680897Z","shell.execute_reply.started":"2025-01-15T13:05:53.620540Z","shell.execute_reply":"2025-01-15T13:05:53.679936Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"path = Path(\"/kaggle/input/iam-handwritten-forms-dataset\")\ndata_path = path/\"data\"","metadata":{"execution":{"iopub.status.busy":"2025-01-15T13:05:53.683145Z","iopub.execute_input":"2025-01-15T13:05:53.683478Z","iopub.status.idle":"2025-01-15T13:05:53.690751Z","shell.execute_reply.started":"2025-01-15T13:05:53.683445Z","shell.execute_reply":"2025-01-15T13:05:53.690047Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_path_list = list(data_path.glob(\"*/*\"))\nrandom_image_path = random.choice(image_path_list)\n\nimage_class = random_image_path.parent.stem\n\nimg = Image.open(random_image_path)\n\nprint(f\"Random Image Path : {random_image_path}\")\nprint(f\"Image Class : {image_class}\")\nprint(f\"Image Height : {img.height}\")\nprint(f\"Image Width : {img.width}\")\nimg","metadata":{"execution":{"iopub.status.busy":"2025-01-15T13:05:53.691627Z","iopub.execute_input":"2025-01-15T13:05:53.691838Z","iopub.status.idle":"2025-01-15T13:05:54.678186Z","shell.execute_reply.started":"2025-01-15T13:05:53.691821Z","shell.execute_reply":"2025-01-15T13:05:54.677191Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_transforms = transforms.Compose([\n    transforms.Grayscale(num_output_channels = 1),\n    transforms.Resize((128,128)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,),(0.5,))\n])\nimage_transforms","metadata":{"execution":{"iopub.status.busy":"2025-01-15T13:05:54.679448Z","iopub.execute_input":"2025-01-15T13:05:54.679680Z","iopub.status.idle":"2025-01-15T13:05:54.685342Z","shell.execute_reply.started":"2025-01-15T13:05:54.679661Z","shell.execute_reply":"2025-01-15T13:05:54.684643Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_transformed_image(image_paths,transform,n=3,seed=42):\n    random.seed(seed)\n    random_image_paths = random.sample(image_paths,k=n)\n    for image_path in random_image_paths:\n        with Image.open(image_path) as f:\n            fig,ax = plt.subplots(1,2)\n            ax[0].imshow(f)\n            ax[0].set_title(f\"Original Size : {f.size}\")\n            ax[0].axis(False)\n            transformed_image = transform(f).permute(1,2,0)\n            ax[1].imshow(transformed_image)\n            ax[1].set_title(f\"Transformed \\nsize : {transformed_image.shape}\")\n            ax[1].axis(False)\n            \n            fig.suptitle(f\"Class : {image_path.parent.stem}\",fontsize = 16)","metadata":{"execution":{"iopub.status.busy":"2025-01-15T13:05:54.686203Z","iopub.execute_input":"2025-01-15T13:05:54.686490Z","iopub.status.idle":"2025-01-15T13:05:54.694146Z","shell.execute_reply.started":"2025-01-15T13:05:54.686467Z","shell.execute_reply":"2025-01-15T13:05:54.693262Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_transformed_image(image_path_list,image_transforms)","metadata":{"execution":{"iopub.status.busy":"2025-01-15T13:05:54.695184Z","iopub.execute_input":"2025-01-15T13:05:54.695443Z","iopub.status.idle":"2025-01-15T13:05:57.980667Z","shell.execute_reply.started":"2025-01-15T13:05:54.695425Z","shell.execute_reply":"2025-01-15T13:05:57.979794Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data = datasets.ImageFolder(root = data_path,\n                                 transform = image_transforms,\n                                 target_transform = None)\ntrain_data","metadata":{"execution":{"iopub.status.busy":"2025-01-15T13:05:57.981709Z","iopub.execute_input":"2025-01-15T13:05:57.981995Z","iopub.status.idle":"2025-01-15T13:05:58.323664Z","shell.execute_reply.started":"2025-01-15T13:05:57.981974Z","shell.execute_reply":"2025-01-15T13:05:58.322918Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Splitting Data for Faster Experiment.\n\"\"\"subset_size = 250\ndataset_size = len(train_data)\n\nif subset_size > dataset_size:\n    subset_size = dataset_size\n\n# Split the dataset into subset and remaining\nsubset, _ = random_split(train_data, [subset_size, dataset_size - subset_size])\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2025-01-15T13:05:58.324483Z","iopub.execute_input":"2025-01-15T13:05:58.324693Z","iopub.status.idle":"2025-01-15T13:05:58.329621Z","shell.execute_reply.started":"2025-01-15T13:05:58.324676Z","shell.execute_reply":"2025-01-15T13:05:58.328800Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_size = int(0.2 * len(train_data))  # 20% of the data for validation\ntrain_size = len(train_data) - val_size\n\ntrain_subset, val_subset = random_split(train_data, [train_size, val_size])","metadata":{"execution":{"iopub.status.busy":"2025-01-15T13:05:58.330651Z","iopub.execute_input":"2025-01-15T13:05:58.330866Z","iopub.status.idle":"2025-01-15T13:05:58.344554Z","shell.execute_reply.started":"2025-01-15T13:05:58.330849Z","shell.execute_reply":"2025-01-15T13:05:58.343873Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(train_subset) , len(val_subset)","metadata":{"execution":{"iopub.status.busy":"2025-01-15T13:05:58.345444Z","iopub.execute_input":"2025-01-15T13:05:58.345638Z","iopub.status.idle":"2025-01-15T13:05:58.350811Z","shell.execute_reply.started":"2025-01-15T13:05:58.345622Z","shell.execute_reply":"2025-01-15T13:05:58.349958Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Creating DataLoaders\ntrain_dataloader = DataLoader(dataset = train_subset,\n                             batch_size = 32,\n                             shuffle=True,\n                             num_workers = os.cpu_count())\nval_dataloader = DataLoader(dataset = val_subset,\n                           batch_size = 32,\n                           shuffle = False,\n                           num_workers = os.cpu_count())\n\ntrain_dataloader , val_dataloader","metadata":{"execution":{"iopub.status.busy":"2025-01-15T13:05:58.353431Z","iopub.execute_input":"2025-01-15T13:05:58.353666Z","iopub.status.idle":"2025-01-15T13:05:58.361601Z","shell.execute_reply.started":"2025-01-15T13:05:58.353647Z","shell.execute_reply":"2025-01-15T13:05:58.360882Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image,label = train_data[0]\nplt.imshow(transforms.ToPILImage()(image),cmap=\"gray\")\nplt.title(f\"Label : {label}\")\nplt.axis(False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2025-01-15T13:05:58.362544Z","iopub.execute_input":"2025-01-15T13:05:58.362781Z","iopub.status.idle":"2025-01-15T13:05:58.679671Z","shell.execute_reply.started":"2025-01-15T13:05:58.362763Z","shell.execute_reply":"2025-01-15T13:05:58.678836Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Creating Preprocess_image to improve image quality before extracting text\ndef preprocess_image(image):\n    if image.mode != 'RGB':\n        image = image.convert('RGB')\n    \n    image_array = np.array(image)\n    \n    gray_image = cv2.cvtColor(image_array,cv2.COLOR_RGB2GRAY)\n    \n    _,thresh_image = cv2.threshold(gray_image,0,255,cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n    \n    return thresh_image\n\ndef extract_text_from_image(image):\n    preprocessed_image = preprocess_image(image)\n    pil_image = Image.fromarray(preprocessed_image)\n    text = pytesseract.image_to_string(pil_image,config='--psm 11')\n    return text.strip()","metadata":{"execution":{"iopub.status.busy":"2025-01-15T13:05:58.680810Z","iopub.execute_input":"2025-01-15T13:05:58.681156Z","iopub.status.idle":"2025-01-15T13:05:58.687189Z","shell.execute_reply.started":"2025-01-15T13:05:58.681126Z","shell.execute_reply":"2025-01-15T13:05:58.686292Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_path_list = list(data_path.glob(\"*/*\"))\nrandom_image_path = random.choice(image_path_list)\nimage = Image.open(random_image_path)\n\nextracted_text = extract_text_from_image(image)\nprint(f\"Extracted Image : {extracted_text}\")","metadata":{"execution":{"iopub.status.busy":"2025-01-15T13:05:58.688167Z","iopub.execute_input":"2025-01-15T13:05:58.688490Z","iopub.status.idle":"2025-01-15T13:06:00.855319Z","shell.execute_reply.started":"2025-01-15T13:05:58.688469Z","shell.execute_reply":"2025-01-15T13:06:00.854466Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image","metadata":{"execution":{"iopub.status.busy":"2025-01-15T13:06:00.856381Z","iopub.execute_input":"2025-01-15T13:06:00.856647Z","iopub.status.idle":"2025-01-15T13:06:01.979628Z","shell.execute_reply.started":"2025-01-15T13:06:00.856625Z","shell.execute_reply":"2025-01-15T13:06:01.978282Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## HandWritingRNN class\nclass HandWritingRNN(nn.Module):\n    def __init__(self,\n                input_shape : int,\n                hidden_units : int,\n                output_shape : int,\n                num_layers : int = 1):\n        super(HandWritingRNN,self).__init__()\n        self.hidden_units = hidden_units\n        self.num_layers = num_layers\n        self.RNN = nn.LSTM(input_shape,\n                          hidden_units,\n                          num_layers,\n                          batch_first = True)\n        self.FC = nn.Linear(hidden_units,\n                           output_shape)\n    def forward(self,x,hidden):\n        out,hidden = self.RNN(x,hidden)\n        out = self.FC(out)\n        return out,hidden\n    \n    def init_hidden(self,batch_size,device):\n        return (torch.zeros(self.num_layers,batch_size,self.hidden_units,device = device),\n               torch.zeros(self.num_layers,batch_size,self.hidden_units,device = device))","metadata":{"execution":{"iopub.status.busy":"2025-01-15T13:06:01.980740Z","iopub.execute_input":"2025-01-15T13:06:01.981039Z","iopub.status.idle":"2025-01-15T13:06:01.990511Z","shell.execute_reply.started":"2025-01-15T13:06:01.981016Z","shell.execute_reply":"2025-01-15T13:06:01.989759Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_step(model :torch.nn.Module,\n              dataloader : torch.utils.data.DataLoader,\n              loss_fn : torch.nn.Module,\n              optimizer : torch.optim.Optimizer,\n              device : torch.device):\n    model.train()\n    train_loss = 0.0 \n    \n    for X,_ in dataloader:\n        X = X.to(device)\n        \n        batch_size,channels,height,width = X.size()\n        X = X.view(batch_size,-1) # Flatting Image\n        X = X.unsqueeze(1) # Adding Sequence Dimension\n        \n        hidden = model.init_hidden(X.size(0),device)\n        \n        optimizer.zero_grad()\n        \n        outputs, _ = model(X,hidden)\n        \n        outputs = outputs.squeeze(1) \n        targets = X.view(X.size(0),-1) # flatting the targets\n        \n        loss = loss_fn(outputs , targets)\n        \n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n        \n    return train_loss / len(dataloader)","metadata":{"execution":{"iopub.status.busy":"2025-01-15T13:06:01.991629Z","iopub.execute_input":"2025-01-15T13:06:01.992129Z","iopub.status.idle":"2025-01-15T13:06:02.004383Z","shell.execute_reply.started":"2025-01-15T13:06:01.992102Z","shell.execute_reply":"2025-01-15T13:06:02.003437Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def test_step(model : torch.nn.Module,\n             dataloader : torch.utils.data.DataLoader,\n             loss_fn : torch.nn.Module,\n             device = torch.device):\n    model.eval()\n    test_loss = 0.0 \n    with torch.inference_mode():\n        for X,_ in dataloader:\n            X = X.to(device)\n            \n            batch_size,channels,height,width = X.size()\n            X = X.view(batch_size,-1)\n            X = X.unsqueeze(1)\n            \n            hidden = model.init_hidden(X.size(0),device)\n            \n            outputs, _ = model(X, hidden)\n\n            # Flatten outputs and targets\n            outputs = outputs.squeeze(1)  # Remove sequence dimension\n            targets = X.view(X.size(0), -1)  # Flatten targets\n\n            loss = loss_fn(outputs, targets)\n            test_loss += loss.item()\n    return test_loss / len(dataloader)","metadata":{"execution":{"iopub.status.busy":"2025-01-15T13:06:02.005765Z","iopub.execute_input":"2025-01-15T13:06:02.006106Z","iopub.status.idle":"2025-01-15T13:06:02.016254Z","shell.execute_reply.started":"2025-01-15T13:06:02.006075Z","shell.execute_reply":"2025-01-15T13:06:02.015605Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train(model: torch.nn.Module,\n          train_dataloader: torch.utils.data.DataLoader,\n          val_dataloader: torch.utils.data.DataLoader,\n          optimizer: torch.optim.Optimizer,\n          loss_fn: torch.nn.Module,\n          device: torch.device,\n          epochs: int = 5):\n    model.to(device)\n    results = {\"train_loss\": [],\n               \"val_loss\": []}\n    \n    for epoch in range(epochs):\n        train_loss = train_step(model, train_dataloader, loss_fn, optimizer, device)\n        val_loss = test_step(model, val_dataloader, loss_fn, device)\n        \n        print(f\"Epoch: {epoch + 1} | train_loss: {train_loss:.3f} | val_loss: {val_loss:.3f}\")\n        results[\"train_loss\"].append(train_loss)\n        results[\"val_loss\"].append(val_loss)\n    \n    return results\n","metadata":{"execution":{"iopub.status.busy":"2025-01-15T13:06:02.017271Z","iopub.execute_input":"2025-01-15T13:06:02.017558Z","iopub.status.idle":"2025-01-15T13:06:02.026412Z","shell.execute_reply.started":"2025-01-15T13:06:02.017532Z","shell.execute_reply":"2025-01-15T13:06:02.025616Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"input_shape = 128*128\noutput_shape = input_shape\nhidden_units = 256\nnum_layers = 2\nmodel = HandWritingRNN(input_shape = input_shape,\n                      output_shape = output_shape,\n                      hidden_units = hidden_units,\n                      num_layers = num_layers)\nloss_fn = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(),lr=0.002)\ntorch.manual_seed(42)\ntorch.cuda.manual_seed(42)\n\nstart_time = timer()\n\nmodel_results = train(model, train_dataloader, val_dataloader, optimizer, loss_fn, epochs=5, device=device)\n\nend_time = timer()\n\nprint(f\"Total Training Time : {end_time - start_time:.3f}seconds\")","metadata":{"execution":{"iopub.status.busy":"2025-01-15T13:06:02.027526Z","iopub.execute_input":"2025-01-15T13:06:02.027753Z","iopub.status.idle":"2025-01-15T13:10:32.875576Z","shell.execute_reply.started":"2025-01-15T13:06:02.027734Z","shell.execute_reply":"2025-01-15T13:10:32.874352Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn.functional as F\ndef sample(predictions, temperature=1.0):\n    predictions = predictions / temperature\n    probabilities = F.softmax(predictions, dim=-1)\n    return torch.multinomial(probabilities, 1).item()","metadata":{"execution":{"iopub.status.busy":"2025-01-15T13:10:32.877106Z","iopub.execute_input":"2025-01-15T13:10:32.877506Z","iopub.status.idle":"2025-01-15T13:10:32.883419Z","shell.execute_reply.started":"2025-01-15T13:10:32.877473Z","shell.execute_reply":"2025-01-15T13:10:32.882275Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn.functional as F\ndef generate_text(model, seed_text, max_length, device, temperature=1.0):\n    model.eval()\n    generated_text = seed_text\n    \n    # Converting Textv into tensor\n    seed_tensor = torch.tensor([ord(char) for char in seed_text], dtype=torch.float32).unsqueeze(0).to(device)\n\n    if seed_tensor.size(-1) < 16384:\n        padding_size = 16384 - seed_tensor.size(-1)\n        seed_tensor = F.pad(seed_tensor, (0, padding_size), 'constant', 0)\n    else:\n        seed_tensor = seed_tensor[:, :16384]\n    \n    seed_tensor = seed_tensor.unsqueeze(1)  \n\n    hidden = model.init_hidden(seed_tensor.size(0), device)\n\n    print(f\"Initial seed_tensor shape: {seed_tensor.shape}\")\n    print(f\"Initial Hidden state shape: {hidden[0].shape}, {hidden[1].shape}\")\n\n    with torch.no_grad():\n        for _ in range(max_length):\n            output, hidden = model(seed_tensor, hidden)\n\n            output = output.squeeze(1) \n            predictions = output[-1] \n\n            predicted_char_index = sample(predictions, temperature)\n            predicted_char = chr(predicted_char_index)\n            generated_text += predicted_char\n\n            # Update seed tensor with the new character\n            new_char_tensor = torch.tensor([ord(predicted_char)], dtype=torch.float32).unsqueeze(0).to(device)\n            new_char_tensor = F.pad(new_char_tensor, (0, 16384 - new_char_tensor.size(-1)), 'constant', 0)\n            new_char_tensor = new_char_tensor.unsqueeze(1)\n\n            # Slide the window to include the new character\n            seed_tensor = torch.cat((seed_tensor[:, 1:, :], new_char_tensor), dim=1)\n\n    return generated_text","metadata":{"execution":{"iopub.status.busy":"2025-01-15T13:10:32.884644Z","iopub.execute_input":"2025-01-15T13:10:32.884951Z","iopub.status.idle":"2025-01-15T13:10:32.895854Z","shell.execute_reply.started":"2025-01-15T13:10:32.884926Z","shell.execute_reply":"2025-01-15T13:10:32.894897Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seed_text = extracted_text\nmax_length = 200\ntemperature = 0.8\nmodel.to(device)\ngenerated_text = generate_text(model, seed_text, max_length, device)\nprint(f\"Generated text: {generated_text}\")","metadata":{"execution":{"iopub.status.busy":"2025-01-15T13:10:32.896912Z","iopub.execute_input":"2025-01-15T13:10:32.897251Z","iopub.status.idle":"2025-01-15T13:10:33.283555Z","shell.execute_reply.started":"2025-01-15T13:10:32.897223Z","shell.execute_reply":"2025-01-15T13:10:33.282652Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(model.state_dict(), \"handwriting_model.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T13:18:54.784525Z","iopub.execute_input":"2025-01-15T13:18:54.784860Z","iopub.status.idle":"2025-01-15T13:18:54.968567Z","shell.execute_reply.started":"2025-01-15T13:18:54.784838Z","shell.execute_reply":"2025-01-15T13:18:54.967591Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = HandWritingRNN(input_shape=128*128, output_shape=128*128, hidden_units=256, num_layers=2)\nmodel.load_state_dict(torch.load(\"handwriting_model.pth\"))\nmodel.eval()  # Modelin değerlendirme moduna alınması","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T13:19:11.134621Z","iopub.execute_input":"2025-01-15T13:19:11.134940Z","iopub.status.idle":"2025-01-15T13:19:11.425608Z","shell.execute_reply.started":"2025-01-15T13:19:11.134916Z","shell.execute_reply":"2025-01-15T13:19:11.424620Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i in range(38, 70):  # 38'den 40'a kadar (son rakam dahil) döngü ile işlem yapacağız\n    image_path = f\"/kaggle/input/files-png/img/Document 30042018_{i}.jpg\"  # Dosya yolunu güncelliyoruz\n    image = Image.open(image_path)  # Resmi yüklüyoruz\n    extracted_text = extract_text_from_image(image)  # El yazısından metin çıkarma\n    print(f\"Extracted Text from Document 30042018_{i}.jpg: {extracted_text}\")\n    print(\"----------------------------------------------\")\n","metadata":{"trusted":true,"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i in range(69, 71):  # 38'den 40'a kadar (son rakam dahil) döngü ile işlem yapacağız\n    image_path = f\"/kaggle/input/files-png/img/Document 30042018_{i}.jpg\"  # Dosya yolunu güncelliyoruz\n    image = Image.open(image_path)  # Resmi yüklüyoruz\n    extracted_text = extract_text_from_image(image)  # El yazısından metin çıkarma\n    print(f\"Extracted Text from Document 30042018_{i}.jpg: {extracted_text}\")\n    print(\"----------------------------------------------\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T13:36:52.690096Z","iopub.execute_input":"2025-01-15T13:36:52.690738Z","iopub.status.idle":"2025-01-15T13:36:54.217522Z","shell.execute_reply.started":"2025-01-15T13:36:52.690704Z","shell.execute_reply":"2025-01-15T13:36:54.216653Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_path = f\"/kaggle/input/imgbin/imgbin-text-document-writing-english-information-family-quote-45PiHQd67YrAs0ez1VnQBC7EX.jpg\"  # Dosya yolunu güncelliyoruz\nimage = Image.open(image_path)  # Resmi yüklüyoruz\nextracted_text = extract_text_from_image(image)  # El yazısından metin çıkarma\nprint(f\"Extracted Text from Document 30042018_{i}.jpg: {extracted_text}\") \nprint(\"----------------------------------------------\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T13:39:29.566286Z","iopub.execute_input":"2025-01-15T13:39:29.567124Z","iopub.status.idle":"2025-01-15T13:39:29.795822Z","shell.execute_reply.started":"2025-01-15T13:39:29.567097Z","shell.execute_reply":"2025-01-15T13:39:29.794940Z"}},"outputs":[],"execution_count":null}]}